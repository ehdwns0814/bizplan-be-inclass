# [#008] REQ-FUNC-003-AI-001: ì‚¬ì—…ê³„íšì„œ ìƒì„± LLM ì—”ì§„ (FastAPI)

## ğŸ“‹ Issue Metadata
- **Issue Number**: #008
- **Epic**: EPIC 1 - ê³¼ì œ í†µê³¼ Job (To pass the test)
- **Type**: `feature`
- **Component**: `ai`, `fastapi`, `llm`
- **Priority**: `Must`
- **Estimated Effort**: L
- **Parallelizable**: âœ… Yes (Can develop independently, integrates with #009)

## ğŸ¯ ëª©ì 
ì‚¬ìš©ì ë‹µë³€ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì—…ê³„íšì„œë¥¼ ìƒì„±í•˜ëŠ” LLM ê¸°ë°˜ ì—”ì§„ì„ FastAPIë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.

## ğŸ“ ì„¤ëª…
Wizardì—ì„œ ìˆ˜ì§‘í•œ ë‹µë³€ ë°ì´í„°ë¥¼ ì…ë ¥ë°›ì•„ LLM(GPT-4, Claude ë“±)ì„ í™œìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ì‚¬ì—…ê³„íšì„œë¥¼ ìƒì„±í•˜ëŠ” AI ì„œë¹„ìŠ¤ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.

## âœ… ë²”ìœ„ (In-Scope)
- FastAPI ê¸°ë°˜ LLM ì„œë¹„ìŠ¤ êµ¬ì¶•
- LLM Prompt Engineering
- ë¬¸ì„œ êµ¬ì¡°í™” (ì„¹ì…˜ë³„ ìƒì„±)
- API Endpoint (`POST /api/v1/generate-bizplan`)
- ë¹„ë™ê¸° ì²˜ë¦¬ (Celery/RQ)

## âŒ ì œì™¸ ë²”ìœ„ (Out-of-Scope)
- ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° (MVP ë‹¨ê³„)
- ë‹¤êµ­ì–´ ì§€ì›
- ì»¤ìŠ¤í…€ LLM íŒŒì¸íŠœë‹

## ğŸ”¨ êµ¬í˜„ íŒíŠ¸
1. **Project Structure**:
   ```
   fastapi_llm_service/
   â”œâ”€â”€ main.py
   â”œâ”€â”€ routers/
   â”‚   â””â”€â”€ bizplan.py
   â”œâ”€â”€ services/
   â”‚   â”œâ”€â”€ llm_service.py
   â”‚   â””â”€â”€ prompt_templates.py
   â”œâ”€â”€ models/
   â”‚   â”œâ”€â”€ request_models.py
   â”‚   â””â”€â”€ response_models.py
   â””â”€â”€ config/
       â””â”€â”€ settings.py
   ```

2. **API Endpoint**:
   ```python
   @router.post("/api/v1/generate-bizplan")
   async def generate_bizplan(request: BizPlanRequest):
       # LLM í˜¸ì¶œ ë° ë¬¸ì„œ ìƒì„±
       pass
   ```

3. **Prompt Template Example**:
   ```python
   BIZPLAN_PROMPT = """
   ë‹¤ìŒ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì—…ê³„íšì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
   - ì‚¬ì—… ì•„ì´ë””ì–´: {idea}
   - íƒ€ê²Ÿ ì‹œì¥: {target_market}
   - ì˜ˆìƒ ë§¤ì¶œ: {revenue}
   ...
   """
   ```

4. **LLM Integration**:
   - OpenAI API ë˜ëŠ” Anthropic API ì‚¬ìš©
   - ì„¹ì…˜ë³„ ìƒì„± (Executive Summary, Market Analysis, etc.)
   - JSON ì‘ë‹µ êµ¬ì¡°í™”

## âœ… ì™„ë£Œ ì¡°ê±´
- [ ] FastAPI ì„œë¹„ìŠ¤ êµ¬ì¶• ì™„ë£Œ
- [ ] LLM API ì—°ë™ ì™„ë£Œ
- [ ] Prompt Template ì‘ì„± ë° í…ŒìŠ¤íŠ¸
- [ ] ë¬¸ì„œ êµ¬ì¡°í™” ë¡œì§ êµ¬í˜„
- [ ] ë¹„ë™ê¸° ì²˜ë¦¬ êµ¬í˜„ (Celery/RQ)
- [ ] Unit Tests ì‘ì„±
- [ ] Integration Tests ì‘ì„±
- [ ] API Documentation (Swagger/ReDoc)
- [ ] í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (.env)

## ğŸ”— ì˜ì¡´ì„±
- **Depends on**: #007 (ë‹µë³€ ë°ì´í„° êµ¬ì¡° íŒŒì•… í•„ìš”)
- **Blocks**: #009 (Spring Boot ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜)

## ğŸ§ª í…ŒìŠ¤íŠ¸
### Unit Tests
```python
def test_generate_bizplan_success():
    # Given
    mock_answers = {...}
    # When
    result = llm_service.generate(mock_answers)
    # Then
    assert result['sections'] is not None
```

### Integration Tests
```python
@pytest.mark.asyncio
async def test_bizplan_api_endpoint():
    response = await client.post("/api/v1/generate-bizplan", json=payload)
    assert response.status_code == 200
```

## ğŸ“… ë¡œë“œë§µ
- **Phase**: Phase 3 (AI Pipeline)
- **Parallel Group**: AI Development (Can develop independently)

## ğŸ·ï¸ Labels
`epic-1`, `ai`, `fastapi`, `llm`, `feature`, `priority-must`

## ğŸ“‹ Environment Variables
```env
OPENAI_API_KEY=your_api_key
LLM_MODEL=gpt-4
LLM_TEMPERATURE=0.7
MAX_TOKENS=4000
```

## ğŸ”§ Dependencies
```txt
fastapi==0.109.0
uvicorn==0.27.0
openai==1.10.0
pydantic==2.5.3
celery==5.3.4
redis==5.0.1
```

---
**Related Tasks**: #007, #009
**Execution Order**: Phase 3 - Parallel (AI Development)

